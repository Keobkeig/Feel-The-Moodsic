# Feel-The-Moodsic
As presented at BigRedHack's 2025 Makeathon, Feel-The-Moodsic is a neural network model that detects the song playing aloud and returns a color represented by the mood of the song in real-time. The model is trained on the [Spotify 2018 and 2019 Audio Features Dataset](https://www.kaggle.com/datasets/tomigelo/spotify-audio-features/code). 

[Canva Presentation](https://www.canva.com/design/DAGf7fzHW-I/oSiedIczd21f_-vHhqm49Q/edit?utm_content=DAGf7fzHW-I&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)

## High Level Diagram

<img width="1113" alt="image" src="https://github.com/user-attachments/assets/2a3d2c8e-150c-4214-89d5-c61de5d14951" />

## Model Results

<img width="1165" alt="image" src="https://github.com/user-attachments/assets/17aa283d-eaaf-4718-9258-a8b8593f0c17" />
